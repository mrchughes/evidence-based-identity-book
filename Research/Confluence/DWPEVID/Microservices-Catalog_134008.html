<!DOCTYPE html>
<html>
    <head>
        <title>DCS Evidence-Based Identity Platform : Microservices Catalog</title>
        <link rel="stylesheet" href="styles/site.css" type="text/css" />
        <META http-equiv="Content-Type" content="text/html; charset=UTF-8">
    </head>

    <body class="theme-default aui-theme-default">
        <div id="page">
            <div id="main" class="aui-page-panel">
                <div id="main-header">
                    <div id="breadcrumb-section">
                        <ol id="breadcrumbs">
                            <li class="first">
                                <span><a href="index.html">DCS Evidence-Based Identity Platform</a></span>
                            </li>
                                                    <li>
                                <span><a href="Building-Evidence-Based-Services-for-a-Unified-Citizen-Experience_68910.html">Building Evidence-Based Services for a Unified Citizen Experience</a></span>
                            </li>
                                                    <li>
                                <span><a href="Application-Architecture_133940.html">Application Architecture</a></span>
                            </li>
                                                </ol>
                    </div>
                    <h1 id="title-heading" class="pagetitle">
                                                <span id="title-text">
                            DCS Evidence-Based Identity Platform : Microservices Catalog
                        </span>
                    </h1>
                </div>

                <div id="content" class="view">
                    <div class="page-metadata">
                            
        
    
        
    
        
        
            Created by <span class='author'> Christian Hughes</span>, last modified on Sept 15, 2025
                        </div>
                    <div id="main-content" class="wiki-content group">
                    <h2 id="MicroservicesCatalog-EvidenceIngestionService">Evidence Ingestion Service</h2><p><strong>Technology Stack</strong>: Node.js 18 with TypeScript, Express.js framework, Apache Tika for document processing, Tesseract OCR for text extraction, Web Crypto API for signature verification</p><p><strong>Service Responsibilities</strong>: Transforms all incoming evidence from diverse sources into standardized RDF assertions with complete provenance metadata. Handles document uploads from citizens, structured API submissions from external partners, and bulk data feeds from government systems while maintaining consistent quality assessment and confidence scoring.</p><p><strong>Core APIs</strong>:</p><ul><li><p><code>POST /evidence/document</code> - Process uploaded documents through OCR and assertion extraction</p></li><li><p><code>POST /evidence/assertion</code> - Accept structured assertions from trusted systems</p></li><li><p><code>POST /evidence/bulk</code> - Handle high-volume batch processing from external feeds</p></li><li><p><code>GET /evidence/{id}/status</code> - Provide real-time processing status updates</p></li><li><p><code>DELETE /evidence/{id}</code> - Manage evidence withdrawal and impact assessment</p></li></ul><p><strong>Data Dependencies</strong>: Triple store for assertion storage, Kafka for event publishing, Redis for processing status caching, MongoDB for document metadata and processing logs</p><p><strong>Integration Points</strong>: Identity Resolution Service for subject correlation, Audit Service for comprehensive logging, External Integration Gateway for partner submissions</p><p><strong>Scaling Characteristics</strong>: CPU-intensive during document processing, scales horizontally through containerized workers, requires significant storage for document retention and processing queues</p><p><strong>Security Controls</strong>: Input validation for all document types, virus scanning through ClamAV integration, rate limiting per user and organization, comprehensive audit logging of all evidence handling</p><h2 id="MicroservicesCatalog-IdentityResolutionService">Identity Resolution Service</h2><p><strong>Technology Stack</strong>: Python 3.11, FastAPI for REST APIs, scikit-learn for machine learning models, spaCy for natural language processing, NetworkX for graph analysis, Redis for cluster caching</p><p><strong>Service Responsibilities</strong>: Manages probabilistic identity clustering through sophisticated algorithms that correlate evidence across different subject identifiers. Handles DID correlation scenarios where citizens use multiple digital identities while preserving privacy choices about service separation.</p><p><strong>Core APIs</strong>:</p><ul><li><p><code>POST /identity/cluster</code> - Trigger identity clustering algorithms for new or updated evidence</p></li><li><p><code>GET /identity/cluster/{id}</code> - Retrieve comprehensive cluster details and confidence metadata</p></li><li><p><code>POST /identity/correlate-dids</code> - Analyze potential correlations between different DIDs</p></li><li><p><code>GET /identity/confidence/{subject}</code> - Provide real-time confidence scoring for identity determinations</p></li><li><p><code>POST /identity/split-cluster</code> - Handle cluster separation when investigation reveals incorrect merging</p></li></ul><p><strong>Machine Learning Models</strong>:</p><ul><li><p>Fuzzy string matching algorithms for name and address correlation</p></li><li><p>Temporal analysis models for date of birth and event timeline correlation</p></li><li><p>Graph clustering algorithms for relationship pattern detection</p></li><li><p>Confidence scoring models that account for evidence quality and correlation strength</p></li></ul><p><strong>Data Dependencies</strong>: Triple store for identity cluster storage, Redis for hot cluster caching, PostgreSQL for ML model versioning, Elasticsearch for similarity search optimization</p><p><strong>Integration Points</strong>: Evidence Ingestion for correlation triggers, Semantic Translation for cross-product identity verification, Investigation Queue for confidence threshold violations</p><p><strong>Performance Characteristics</strong>: Memory-intensive for graph processing, benefits from GPU acceleration for ML workloads, implements intelligent caching for frequently accessed clusters</p><h2 id="MicroservicesCatalog-SemanticTranslationService">Semantic Translation Service</h2><p><strong>Technology Stack</strong>: Java 17, Spring Boot framework, Apache Jena for RDF processing, OWL API for ontology management, HermiT reasoner for logical inference, GraphQL for flexible query interfaces</p><p><strong>Service Responsibilities</strong>: Applies formal ontologies to enable evidence sharing between different policy contexts while preserving semantic meaning and confidence levels. Implements sophisticated reasoning capabilities that derive new assertions from existing evidence combinations.</p><p><strong>Core APIs</strong>:</p><ul><li><p><code>POST /semantic/translate</code> - Convert evidence between different product vocabularies</p></li><li><p><code>GET /semantic/ontology/{product}</code> - Retrieve formal ontology definitions for specific DCS products</p></li><li><p><code>POST /semantic/validate</code> - Validate assertions against SHACL shape constraints</p></li><li><p><code>POST /semantic/reasoning</code> - Apply OWL reasoning to derive new assertions from existing evidence</p></li><li><p><code>PUT /semantic/mapping</code> - Update cross-product semantic mappings with appropriate approval workflows</p></li></ul><p><strong>Ontology Management</strong>:</p><ul><li><p>DCS Core Ontology defining base classes for assertions, evidence, and identity</p></li><li><p>Product-specific ontologies for BasicSupport, FamilyAssist, AgeCare vocabularies</p></li><li><p>External partner ontologies for HMRC, local authority, and healthcare provider concepts</p></li><li><p>Formal semantic mappings between different vocabulary systems with confidence weighting</p></li></ul><p><strong>Data Dependencies</strong>: Dedicated triple store partition for ontology storage, Redis for translation result caching, PostgreSQL for ontology version control and change management</p><p><strong>Integration Points</strong>: All other services require semantic translation for cross-context evidence sharing, External Integration Gateway for partner vocabulary translation</p><p><strong>Reasoning Capabilities</strong>: Automated derivation of new assertions through logical inference, consistency checking across different evidence sources, confidence propagation through reasoning chains</p><h2 id="MicroservicesCatalog-AwardCalculationService">Award Calculation Service</h2><p><strong>Technology Stack</strong>: Java 17, Spring Boot with Spring Security, Drools rule engine for policy implementation, PostgreSQL for award storage, Kafka for event streaming</p><p><strong>Service Responsibilities</strong>: Implements sophisticated policy engines that determine benefit entitlements based on available evidence and confidence thresholds. Handles complex eligibility criteria, historical recalculation, and simulation capabilities for policy testing and citizen guidance.</p><p><strong>Core APIs</strong>:</p><ul><li><p><code>POST /awards/calculate</code> - Perform comprehensive entitlement calculation for identity clusters</p></li><li><p><code>POST /awards/recalculate</code> - Handle retrospective changes when new evidence affects historical periods</p></li><li><p><code>GET /awards/{clusterid}</code> - Retrieve current and historical award information</p></li><li><p><code>POST /awards/simulate</code> - Enable &quot;what-if&quot; analysis for policy testing and citizen guidance</p></li><li><p><code>PUT /awards/{id}/suspend</code> - Suspend awards when confidence drops below required thresholds</p></li></ul><p><strong>Policy Engine Architecture</strong>:</p><ul><li><p>Drools rule sets for each benefit type with modular organization enabling independent updates</p></li><li><p>Confidence threshold configuration per benefit type and award amount</p></li><li><p>Historical recalculation logic that identifies affected periods and applies appropriate business rules</p></li><li><p>Integration with external rate tables and policy parameter databases</p></li></ul><p><strong>Data Dependencies</strong>: PostgreSQL for calculated awards and payment schedules, Redis for calculation result caching, Triple store for evidence queries, Kafka for award change notifications</p><p><strong>Integration Points</strong>: Identity Resolution for confidence assessment, Semantic Translation for evidence interpretation, Investigation Queue for threshold violations, Notification Service for citizen communication</p><p><strong>Business Rule Management</strong>: Version-controlled policy rules with audit trails, A/B testing capabilities for rule optimization, comprehensive impact analysis for policy changes</p><h2 id="MicroservicesCatalog-InvestigationQueueService">Investigation Queue Service</h2><p><strong>Technology Stack</strong>: Go 1.21, Gin framework for REST APIs, <a href="http://Temporal.io" data-card-appearance="inline" class="external-link" rel="nofollow">http://Temporal.io</a>  for workflow orchestration, MongoDB for case management, Redis for queue optimization</p><p><strong>Service Responsibilities</strong>: Manages sophisticated exception workflows when confidence levels are insufficient for automated processing or when evidence conflicts require human intervention. Implements intelligent case prioritization and skill-based routing to ensure human attention focuses where it adds most value.</p><p><strong>Core APIs</strong>:</p><ul><li><p><code>GET /investigations/queue</code> - Retrieve prioritized investigation cases based on caseworker skills and workload</p></li><li><p><code>POST /investigations/{id}/assign</code> - Assign investigations with skill matching and workload balancing</p></li><li><p><code>PUT /investigations/{id}/resolve</code> - Capture investigation outcomes and trigger follow-up actions</p></li><li><p><code>POST /investigations/create</code> - Create investigation cases from automated triggers or manual referrals</p></li><li><p><code>PUT /investigations/{id}/escalate</code> - Handle complex cases requiring senior review or specialist expertise</p></li></ul><p><strong>Workflow Management</strong>:</p><ul><li><p><a href="http://Temporal.io" data-card-appearance="inline" class="external-link" rel="nofollow">http://Temporal.io</a>  workflows for complex investigation processes with state management</p></li><li><p>Priority scoring algorithms that account for financial impact, fraud risk, and citizen vulnerability</p></li><li><p>Skill-based routing that matches case types to caseworker expertise and security clearances</p></li><li><p>Automated escalation procedures with configurable timeframes and approval hierarchies</p></li></ul><p><strong>Data Dependencies</strong>: MongoDB for flexible case document storage, Redis for queue performance optimization, PostgreSQL for caseworker skill profiles and workload tracking</p><p><strong>Integration Points</strong>: All services can trigger investigations, Identity Resolution for confidence threshold monitoring, Award Calculation for award impact assessment, Notification Service for citizen and caseworker communication</p><p><strong>Performance Optimization</strong>: Intelligent queue management that reduces caseworker context switching, predictive analytics for capacity planning, automated case categorization to improve routing efficiency</p><h2 id="MicroservicesCatalog-NotificationService">Notification Service</h2><p><strong>Technology Stack</strong>: Node.js 18 with TypeScript, Express.js framework, Redis Bull queues for message processing, AWS SES and <a href="http://GOV.UK" data-card-appearance="inline" class="external-link" rel="nofollow">http://GOV.UK</a>  Notify for delivery, Handlebars.js for templating</p><p><strong>Service Responsibilities</strong>: Manages comprehensive communication with citizens and caseworkers through multiple channels while ensuring messages are appropriate, accessible, and actionable. Handles complex delivery logic based on recipient preferences, message urgency, and accessibility requirements.</p><p><strong>Core APIs</strong>:</p><ul><li><p><code>POST /notifications/send</code> - Deliver notifications with intelligent channel selection and preference handling</p></li><li><p><code>GET /notifications/templates</code> - Retrieve approved message templates with personalization variables</p></li><li><p><code>POST /notifications/preferences</code> - Enable granular control over notification types and delivery methods</p></li><li><p><code>GET /notifications/history/{clusterid}</code> - Provide comprehensive communication audit trails</p></li><li><p><code>POST /notifications/batch</code> - Handle high-volume notification scenarios with rate limiting</p></li></ul><p><strong>Multi-Channel Architecture</strong>:</p><ul><li><p>Email delivery through AWS SES with comprehensive delivery tracking and bounce handling</p></li><li><p>SMS delivery through <a href="http://GOV.UK" data-card-appearance="inline" class="external-link" rel="nofollow">http://GOV.UK</a>  Notify with fallback providers for reliability</p></li><li><p>Postal mail generation through secure printing services with tracking integration</p></li><li><p>In-app notifications through WebSocket connections with offline queuing</p></li><li><p>Secure messaging through citizen portals with end-to-end encryption</p></li></ul><p><strong>Template Management</strong>:</p><ul><li><p>Version-controlled templates that meet accessibility and plain English requirements</p></li><li><p>Multi-language support with automated translation and cultural adaptation</p></li><li><p>Dynamic content personalization based on citizen circumstances and preferences</p></li><li><p>A/B testing capabilities for message effectiveness optimization</p></li></ul><p><strong>Data Dependencies</strong>: Redis for message queuing and delivery status, PostgreSQL for template storage and citizen preferences, MongoDB for delivery audit trails</p><p><strong>Integration Points</strong>: Investigation Queue for case status updates, Award Calculation for award change notifications, Identity Resolution for recipient correlation</p><h2 id="MicroservicesCatalog-AuditandComplianceService">Audit and Compliance Service</h2><p><strong>Technology Stack</strong>: Java 17, Spring Boot with Spring Security, Elasticsearch for log storage and search, PostgreSQL for compliance metadata, Apache POI for report generation</p><p><strong>Service Responsibilities</strong>: Maintains comprehensive audit trails for all platform operations while providing reporting and analysis capabilities required for regulatory compliance, accountability, and continuous improvement. Operates across all platform components to ensure complete visibility into system behavior.</p><p><strong>Core APIs</strong>:</p><ul><li><p><code>GET /audit/trail/{entity-id}</code> - Retrieve complete audit history for any platform entity</p></li><li><p><code>POST /audit/search</code> - Enable complex queries across audit logs with advanced filtering</p></li><li><p><code>GET /audit/compliance-report</code> - Generate regulatory compliance reports with automated scheduling</p></li><li><p><code>POST /audit/retention-policy</code> - Configure data retention according to regulatory requirements</p></li><li><p><code>PUT /audit/anonymize/{entity-id}</code> - Handle data anonymization while preserving audit integrity</p></li></ul><p><strong>Audit Data Model</strong>:</p><ul><li><p>Comprehensive event logging with user attribution, business context, and technical details</p></li><li><p>Immutable audit trails with cryptographic integrity verification</p></li><li><p>Cross-service correlation that links related events across different platform components</p></li><li><p>Performance metrics collection for system optimization and capacity planning</p></li></ul><p><strong>Compliance Capabilities</strong>:</p><ul><li><p>Automated GDPR compliance reporting with data processing activity tracking</p></li><li><p>Equality monitoring reports that analyze decision patterns across demographic groups</p></li><li><p>Fraud prevention audit trails that support investigation and prosecution activities</p></li><li><p>Data retention management that balances accountability with privacy requirements</p></li></ul><p><strong>Data Dependencies</strong>: Elasticsearch cluster for scalable log storage and search, PostgreSQL for compliance configuration and report metadata, Redis for audit event buffering</p><p><strong>Integration Points</strong>: All platform services generate audit events, External Integration Gateway for partner audit requirements, Investigation Queue for case audit trails</p><h2 id="MicroservicesCatalog-ExternalIntegrationGateway">External Integration Gateway</h2><p><strong>Technology Stack</strong>: Go 1.21, Kong API Gateway with custom plugins, OAuth 2.0 and mTLS for authentication, Redis for rate limiting, OpenAPI 3.0 for documentation</p><p><strong>Service Responsibilities</strong>: Provides secure, standardized interfaces for external partners while protecting internal platform operations from external system variations and security threats. Implements comprehensive authentication, authorization, and quality control for high-volume partner integration.</p><p><strong>Core APIs</strong>:</p><ul><li><p><code>POST /external/evidence/submit</code> - Accept verified evidence from trusted external partners</p></li><li><p><code>GET /external/status/{reference}</code> - Provide processing status updates to evidence submitters</p></li><li><p><code>POST /external/bulk/evidence</code> - Handle high-volume batch submissions with progress tracking</p></li><li><p><code>GET /external/schema/{version}</code> - Provide evidence schemas and validation rules for partner integration</p></li><li><p><code>POST /external/webhook/register</code> - Enable partners to receive automated status notifications</p></li></ul><p><strong>Security Architecture</strong>:</p><ul><li><p>OAuth 2.0 client credentials flow for trusted government systems with token validation</p></li><li><p>mTLS certificate authentication for high-security partners with certificate rotation</p></li><li><p>Rate limiting with intelligent throttling based on partner priority and submission quality</p></li><li><p>Comprehensive input validation with schema enforcement and threat detection</p></li></ul><p><strong>Partner Management</strong>:</p><ul><li><p>Self-service partner onboarding with automated testing and validation</p></li><li><p>Comprehensive API documentation with interactive examples and SDK generation</p></li><li><p>Quality monitoring with feedback to partners about submission effectiveness</p></li><li><p>SLA management with performance tracking and issue escalation procedures</p></li></ul><p><strong>Data Dependencies</strong>: Redis for rate limiting and session management, PostgreSQL for partner configuration and API keys, MongoDB for integration logs and error tracking</p><p><strong>Integration Points</strong>: Evidence Ingestion for evidence processing, Identity Resolution for partner identity verification, Audit Service for comprehensive logging of all external interactions</p><p><strong>Quality Assurance</strong>: Automated testing of partner integrations, comprehensive error handling with clear remediation guidance, continuous monitoring of integration health and performance optimization</p><p />
                    </div>

                    
                                                      
                </div>             </div> 
            <div id="footer" role="contentinfo">
                <section class="footer-body">
                    <p>Document generated by Confluence on Sept 27, 2025 09:18</p>
                    <div id="footer-logo"><a href="http://www.atlassian.com/">Atlassian</a></div>
                </section>
            </div>
        </div>     </body>
</html>
